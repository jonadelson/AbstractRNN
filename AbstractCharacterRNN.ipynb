{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import model_from_json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = 'abstracts.csv'\n",
    "\n",
    "def read_and_clean_data():\n",
    "    out = []\n",
    "    with open(file_name) as f:\n",
    "        for i,line in enumerate(f):\n",
    "            abstract = line.strip()\n",
    "            \n",
    "            # The first line is junk until the word During\n",
    "            if i == 0:\n",
    "                abstract = abstract[abstract.find('During'):-1]\n",
    "                \n",
    "            # There are quotes in the data file, remove them\n",
    "            if abstract[0] == '\"' and abstract[-1] == '\"':\n",
    "                abstract = abstract[1:-1]\n",
    "                \n",
    "            out.append(abstract)\n",
    "\n",
    "    # The last line is junk so just return all but that\n",
    "    return out[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abstracts = read_and_clean_data()\n",
    "chars = set([char for abstract in abstracts for char in abstract])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char2idx = {char:idx for idx,char in enumerate(chars)}\n",
    "idx2char = {idx:char for idx,char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_batch_generator(batch_size=30, step=5):\n",
    "    while True:\n",
    "        chars_in = []\n",
    "        chars_out = []\n",
    "        random_abstract = random.randint(0, len(abstracts))\n",
    "        start = random.randint(0, len(abstracts[random_abstract]) - maxlen - 1)\n",
    "        for i in range(batch_size):\n",
    "            chars_in.append(abstracts[random_abstract][start:(start + maxlen)])\n",
    "            chars_out.append(abstracts[random_abstract][start + maxlen])\n",
    "            start = (start + step) % (len(abstracts[random_abstract]) - maxlen - 1) \n",
    "        yield chars_in, chars_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_numerical_batch(batch_size=20, step=5):\n",
    "    gen = data_batch_generator(batch_size, step)\n",
    "    while True:\n",
    "        chars_in, chars_out = next(gen)\n",
    "        X = np.zeros((batch_size, maxlen, len(chars)))\n",
    "        y = np.zeros((batch_size, len(chars)))\n",
    "        for i in range(batch_size):\n",
    "            for j,char in enumerate(chars_in[i]):\n",
    "                X[i,j,char2idx[char]] = 1\n",
    "            y[i,char2idx[chars_out[i]]] = 1\n",
    "        yield X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = gen_numerical_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model_from_json(open('my_model_architecture.json').read())\n",
    "model.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(1.3525692224502563, dtype=float32)]\n",
      "----- Generating with seed: \"In this study we revealed the participat\"\n",
      "In this study we revealed the participation that sentent and acond condention in active merected in memion mate hippocampus and prevention of nelured the the has effects the mediane of heporainesstent and memony senective the prosential and a concentate of ferential medives and surges in the chancentral stented as in neurons a segents and prevention as activity with melores in the changes in allone and parential mas and sevels of deletences inhivity hepertent fantions and the dechamine and activity as siselss of activity the epied ats\n",
      "----- Generating with seed: \"The effects of chloroquine on glial fibr\"\n",
      "The effects of chloroquine on glial fibrated were and mistentormuction sygLinitee alsy in hephoscelition wish stron dellumine of unesis after and peroment mase entabed that and a conciment of the accoupes essypested the sentoless in the appocameuslotical agter in parented dentamented in as surenting inhibity and sentrapetsy a facted as and canceitationally were pardenting as in and memoryenis and te gentents in a ficentivite inoderation in nervestent by ableveston elation of nevelt darule, prosine in the cesciments and the reseont the"
     ]
    }
   ],
   "source": [
    "for j in range(10000):\n",
    "    cost = model.train_on_batch(x,y)\n",
    "    x,y = next(gen)\n",
    "    if j % 100 == 0:\n",
    "        print cost\n",
    "    if j % 2000 == 0:\n",
    "        json_string = model.to_json()\n",
    "        open('my_model_architecture.json', 'w').write(json_string)\n",
    "        model.save_weights('my_model_weights.h5', overwrite=True)\n",
    "        for diversity in [0.5, 0.7, 0.9, 1.0]:\n",
    "            generated = ''\n",
    "            start_index = random.randint(0, len(abstracts) - 1)\n",
    "            sentence = abstracts[start_index][:maxlen]\n",
    "            generated += sentence\n",
    "            print '----- Generating with seed: \"' + sentence + '\"'\n",
    "            next_chars = []\n",
    "            for i in range(500):\n",
    "                z = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    z[0, t, char2idx[char]] = 1.\n",
    "                preds = model.predict(z, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = idx2char[next_index]\n",
    "                sentence = sentence[1:] + next_char\n",
    "                next_chars.append(next_char)\n",
    "            print generated + ''.join(next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "open('my_model_architecture.json', 'w').write(json_string)\n",
    "model.save_weights('my_model_weights.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"Alzheimer's disease (AD) is a degenerati\"\n",
      "Alzheimer's disease (AD) is a degeneration of the verall resporsed the hippocampal resporse the perein the potent dess of the prossis protimin sisuls of intions of the ressing in the partion of the orsers of the ormoroning the controt of the as sulation of the protent atormed the ailoles in the meders of the promed of imizatoros of the proter spows of rens of the proteralic revely of the pasting and ressisted in the pror ass dest trans on of the verall resporsed the hippocampal resporse the perein the potent dess of the prossis protimin sisuls of intions of the ressing in the partion of the orsers of the ormoroning the controt of the as sulation of the protent atormed the ailoles in the meders of the promed of imizatoros of the proter spows of rens of the proteralic revely of the pasting and ressisted in the pror ass dest trans \n"
     ]
    }
   ],
   "source": [
    "generated = ''\n",
    "start_index = random.randint(0, len(abstracts) - 1)\n",
    "sentence = abstracts[start_index][:maxlen]\n",
    "generated += sentence\n",
    "print '----- Generating with seed: \"' + sentence + '\"'\n",
    "next_chars = []\n",
    "for i in range(400):\n",
    "    z = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        z[0, t, char2idx[char]] = 1.\n",
    "    preds = model.predict(z, verbose=0)[0]\n",
    "    next_index = []\n",
    "    for diversity in [0.5, 0.7, 0.9, 1.0]:\n",
    "        next_index.append(sample(preds, diversity))\n",
    "    c = Counter(next_index)\n",
    "    next_index = c.most_common(1)[0][0]\n",
    "    next_char = idx2char[next_index]\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "    next_chars.append(next_char)\n",
    "print generated + ''.join(next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
