{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import model_from_json\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I chose a character that was not in the overall character\n",
    "# set to be the token 'STOP' symbol, to indicate that the \n",
    "# abstract had ended\n",
    "stop_symbol = '\\xe3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = 'abstracts.csv'\n",
    "\n",
    "def read_and_clean_data():\n",
    "    '''\n",
    "    Function to read and clean abstract data\n",
    "    '''\n",
    "    out = []\n",
    "    with open(file_name) as f:\n",
    "        for i,line in enumerate(f):\n",
    "            abstract = line.strip()\n",
    "            \n",
    "            # The first line is junk until the word During\n",
    "            if i == 0:\n",
    "                abstract = abstract[abstract.find('During'):-1]\n",
    "                \n",
    "            # There are quotes in the data file, remove them\n",
    "            if abstract[0] == '\"' and abstract[-1] == '\"':\n",
    "                abstract = abstract[1:-1]\n",
    "                \n",
    "            out.append(abstract + '\\xe3')\n",
    "\n",
    "    # The last line is junk so just return all but that\n",
    "    return out[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abstracts = read_and_clean_data()\n",
    "chars = set([char for abstract in abstracts for char in abstract])\n",
    "char2idx = {char:idx for idx,char in enumerate(chars)} \n",
    "idx2char = {idx:char for idx,char in enumerate(chars)}\n",
    "maxlen = 20 # number of chars to use to predict the next char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_batch_generator(step=5):\n",
    "    '''\n",
    "    This function generates lists of input character sequences as well as \n",
    "    the output character associated with the input sequence. \n",
    "    \n",
    "    Step is number of characters to move forward in the sequence\n",
    "    to get the next sequence\n",
    "    '''\n",
    "\n",
    "    while True:\n",
    "        chars_in = []\n",
    "        chars_out = []\n",
    "        \n",
    "        # choose 10 random abstracts to draw characater sequences from\n",
    "        # 10 is an arbitrarily chosen number\n",
    "        random_abstracts = np.random.randint(0, len(abstracts), 10)\n",
    "        \n",
    "        # Pick random start points, making sure there is sufficient space to get \n",
    "        # a proper sequence\n",
    "        starts = [random.randint(0, len(abstracts[random_abstract]) - maxlen - 1) \n",
    "                 for random_abstract in random_abstracts]\n",
    "        \n",
    "        for i,random_abstract in enumerate(random_abstracts):\n",
    "            # make sure that the abstract is sufficiently long\n",
    "            if len(abstracts[random_abstract]) < (maxlen + 1):\n",
    "                continue\n",
    "            # get five samples from each abstract\n",
    "            for _ in range(5):\n",
    "                chars_in.append(abstracts[random_abstract][starts[i]:(starts[i] + maxlen)])\n",
    "                chars_out.append(abstracts[random_abstract][starts[i] + maxlen])\n",
    "                starts[i] = (starts[i] + step) % (len(abstracts[random_abstract]) - maxlen - 1)\n",
    "        yield chars_in, chars_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_numerical_batch(step=5):\n",
    "    '''\n",
    "    Generates the numerical encoding of the character sequences\n",
    "    '''\n",
    "    gen = data_batch_generator(step)\n",
    "    while True:\n",
    "        chars_in, chars_out = next(gen)\n",
    "        X = np.zeros((len(chars_in), maxlen, len(chars)))\n",
    "        y = np.zeros((len(chars_out), len(chars)))\n",
    "        for i in range(len(chars_in)):\n",
    "            for j,char in enumerate(chars_in[i]):\n",
    "                X[i,j,char2idx[char]] = 1\n",
    "            y[i,char2idx[chars_out[i]]] = 1\n",
    "        yield X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    '''\n",
    "    Helper function to draw a random character\n",
    "    The lower the temperature, the more conservative\n",
    "    the character selection is\n",
    "    '''\n",
    "    a = np.log(a) / temperature\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(512, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(len(chars)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model_from_json(open('my_model_architecture_202.json').read())\n",
    "model.load_weights('my_model_weights_202.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(1.39052152633667, dtype=float32)]\n",
      "----- Generating with seed: \"The immunohistochemi\"\n",
      "The immunohistochemisol experses and septological pathological based on the neurons of response to measure perforant mesperiding substantial such as well as �ychistic leding such as B}, promined the instiant bas not activity and damage was estivated to partial septal growth was also al involved with lipopartial epilepsy 1 had least intractarin to have the anonothermal subunit in ischemic endograating of may induce the activity was reports when edulting conslituitation was revealed in voltabe to the induced increase in control events the proprospatic therefore to a level of the evonematory of rats using the of extracellular sentations. quantifation of ratio also effect response with hippocampal synapse in the concentration of the miceh recordings in the interestivate both normal and propidina of remains slowed that consistent allostoric )ighalin CaNA. A provide control regative resislaring as dongate factors that the coultnol between estial implications were mediated and pathological amygdala receptor and \n",
      "[array(1.6558043956756592, dtype=float32)]\n",
      "[array(1.3021894693374634, dtype=float32)]\n",
      "[array(1.817997694015503, dtype=float32)]\n",
      "[array(1.718460202217102, dtype=float32)]\n",
      "[array(1.2246586084365845, dtype=float32)]\n",
      "[array(1.2653217315673828, dtype=float32)]\n",
      "[array(1.5622897148132324, dtype=float32)]\n",
      "[array(1.0588257312774658, dtype=float32)]\n",
      "[array(1.0777859687805176, dtype=float32)]\n",
      "[array(0.9633936285972595, dtype=float32)]\n",
      "----- Generating with seed: \"Long-term depression\"\n",
      "Long-term depression. The periposary after the non-classion the adpless of �dama enroding indicates that the position of nerve ligand in the hippocampal cortex, HI1 modifies. The structures of the NMDA. In the direct properties of Slave model in extracellular neurons during by caining ollable describes oversal normal induction. Escopolamine }-protein activity in the group and ither the frequency in the rats in the intracellular fiber and functional actions were developed in or free treatments of opioural processess in the similation of spive micrological factor male and attenuated neurovalnetic actions and the strial vascular responses of interaction of a sungies of rat against rats of #-Lyphamia, suggesting that which soges of the dentate gyrus responses were experimental in the present time intermed with lest than �gruction and neurodesensity in the short-term potentiation which synapses, but for exorcis of the noreonal disruption and antibodies is studied in �dentred than �reactic action. �hockty was a\n",
      "[array(1.3526171445846558, dtype=float32)]\n",
      "[array(1.112825870513916, dtype=float32)]\n",
      "[array(1.8331055641174316, dtype=float32)]\n",
      "[array(1.1035070419311523, dtype=float32)]\n",
      "[array(1.280975341796875, dtype=float32)]\n",
      "[array(1.0263909101486206, dtype=float32)]\n",
      "[array(1.6453256607055664, dtype=float32)]\n",
      "[array(1.6147304773330688, dtype=float32)]\n",
      "[array(1.482027530670166, dtype=float32)]\n",
      "[array(1.171913504600525, dtype=float32)]\n",
      "----- Generating with seed: \"The disrupted in sch\"\n",
      "The disrupted in schizophrenic tractola. This this studies of associated ratur was together the process depressant function. These agent. Low a I lateral memory reach to the hippocampal neurons are in synaptic proactivation of experimental longster was mediated by visual cortex and a group disease and suggesting that the sensitional selective (line tau genes were not also induced endogenotyfis in the amplitude of alphazavine-and mice. Thus, may be accompaned by glutamate interneurons between the effect of granular disease brains most activity in conditions unifue blocking and addition. The consultum excitatory syctomy support the concentration) of the results confling that examined cell damage. As on behavioral analysis of sparifical preventions of the confirmologically accumulated by glutamate activity of the compounds the dendritic trial receptor to be same and rats with the behavioral steroin in a spaciul of evidence that the neurons levels that had other long-term studies with response transcription m\n",
      "[array(0.9816902279853821, dtype=float32)]\n",
      "[array(1.5909384489059448, dtype=float32)]\n",
      "[array(0.8328442573547363, dtype=float32)]\n",
      "[array(1.249853253364563, dtype=float32)]\n",
      "[array(1.3573946952819824, dtype=float32)]\n",
      "[array(1.47119140625, dtype=float32)]\n",
      "[array(1.506711483001709, dtype=float32)]\n",
      "[array(1.4160926342010498, dtype=float32)]\n",
      "[array(1.6171574592590332, dtype=float32)]\n",
      "[array(1.50789475440979, dtype=float32)]\n",
      "----- Generating with seed: \"It has been demonstr\"\n",
      "It has been demonstrated a short interform of control produces the paradempered by describe any impaired in the hippocampus, higher the elevation of spine changes in distains and membrane for currance of shom group. Al-detectable serotonin (30--H�) and may be producted in distribution of the donnate and spontaneous and antibodies of the concentration of isoutin (NAB) or KL�T2 and �HK1 may plasticity and in the presence of the neuronal decones to steroid increased endonate the CA1 neuronal cell paradigm and show that increased intically in mice were extoched in a changes that was been significantly if the rats in values. Single , mice postsynaptic acpular by an are studied in the specific male and derective actions and stress approximately steroid tests, are or higher fields of a ndolon, our damability to the ensological calcium assues. This regions of the ateptic decreased normal neurilers for aiming used in the hippocampus. Furthermore, we some of e highly anterior depression and the are consistent in pr\n",
      "[array(1.4041703939437866, dtype=float32)]\n",
      "[array(1.3016853332519531, dtype=float32)]\n",
      "[array(1.3031394481658936, dtype=float32)]\n",
      "[array(1.385739803314209, dtype=float32)]\n",
      "[array(1.6148229837417603, dtype=float32)]\n",
      "[array(1.1869301795959473, dtype=float32)]\n",
      "[array(1.0147799253463745, dtype=float32)]\n",
      "[array(1.5362869501113892, dtype=float32)]\n",
      "[array(1.3425124883651733, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "save_model = False # save every x iterations\n",
    "gen = gen_numerical_batch() # generator for data\n",
    "\n",
    "for j in range(4000):\n",
    "    x,y = next(gen)\n",
    "    cost = model.train_on_batch(x,y)\n",
    "    if j % 100 == 0:\n",
    "        print cost\n",
    "        if save_model:\n",
    "            json_string = model.to_json()\n",
    "            open('my_model_architecture_202.json', 'w').write(json_string)\n",
    "            model.save_weights('my_model_weights_202.h5', overwrite=True)\n",
    "    if j % 1000 == 0:\n",
    "        # originally tried different temperatures, 0.8 works fairly well\n",
    "        for diversity in [0.8]:\n",
    "            generated = ''\n",
    "            start_index = random.randint(0, len(abstracts) - 1) # random abstract to start generating text\n",
    "            sentence = abstracts[start_index][:maxlen] # get first characters\n",
    "            generated += sentence\n",
    "            print '----- Generating with seed: \"' + sentence + '\"'\n",
    "            next_chars = []\n",
    "            for i in range(1000):\n",
    "                z = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    z[0, t, char2idx[char]] = 1.\n",
    "                preds = model.predict(z, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = idx2char[next_index]\n",
    "                sentence = sentence[1:] + next_char\n",
    "                next_chars.append(next_char)\n",
    "            print generated + ''.join(next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
